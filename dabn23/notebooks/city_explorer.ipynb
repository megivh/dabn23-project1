{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d2d81ad",
   "metadata": {},
   "source": [
    "# City Explorer: Multi-Source Attraction & Activity Discovery with Routing\n",
    "\n",
    "This notebook is intentionally **readable** and **step-based**.\n",
    "\n",
    "## What it does\n",
    "1. Loads required environment variables (API keys + DB path)\n",
    "2. Initializes a shared SQLite database (migrations + tables)\n",
    "3. Retrieves **Top 10** items for a city (ranked by review count) from:\n",
    "   - Google Places (New) — tourist attractions\n",
    "   - TripAdvisor Content API — attractions/activities (depending on API behavior)\n",
    "4. Uses a city-level snapshot cache (`city_top10`) and an item-level cache (`item_summary`)\n",
    "5. Provides an interactive UI using **ipywidgets**\n",
    "\n",
    "## Required environment variables\n",
    "- `GOOGLE_MAPS_API_KEY`\n",
    "- `TRIPADVISOR_API_KEY`\n",
    "- `DABN23_DB_PATH` (full file path, e.g. `G:\\My Drive\\dabn23_SharedDatabase\\dabn23_cache.sqlite`)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9831d8b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All required packages are installed.\n"
     ]
    }
   ],
   "source": [
    "# 0) Dependency check (optional)\n",
    "# This notebook does NOT auto-install by default (cleaner + more reproducible).\n",
    "AUTO_INSTALL = False\n",
    "\n",
    "required = [\n",
    "    (\"requests\", \"requests\"),\n",
    "    (\"pandas\", \"pandas\"),\n",
    "    (\"ipywidgets\", \"ipywidgets\"),\n",
    "]\n",
    "\n",
    "missing = []\n",
    "for import_name, pip_name in required:\n",
    "    try:\n",
    "        __import__(import_name)\n",
    "    except ImportError:\n",
    "        missing.append(pip_name)\n",
    "\n",
    "if missing:\n",
    "    print(\"Missing packages:\", \", \".join(missing))\n",
    "    print(\"Install command:\")\n",
    "    print(\"  pip install \" + \" \".join(missing))\n",
    "    if AUTO_INSTALL:\n",
    "        import sys, subprocess\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", *missing])\n",
    "        print(\"Installed. Re-run this cell if needed.\")\n",
    "else:\n",
    "    print(\"All required packages are installed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d8dc7d44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root: c:\\Users\\Samuel\\Desktop\\Git Repo\\dabn23-project1\\dabn23\n"
     ]
    }
   ],
   "source": [
    "# 1) Make sure we can import from /src (works when running from notebooks/ folder)\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "PROJECT_ROOT = Path.cwd().parent if Path.cwd().name == \"notebooks\" else Path.cwd()\n",
    "if str(PROJECT_ROOT) not in sys.path:\n",
    "    sys.path.insert(0, str(PROJECT_ROOT))\n",
    "\n",
    "print(\"Project root:\", PROJECT_ROOT)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db4021eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Google API key loaded (length): 39\n",
      "TripAdvisor API key loaded (length): 32\n",
      "DB_PATH: G:\\My Drive\\dabn23_SharedDatabase\\dabn23_places_cache.sqlite\n"
     ]
    }
   ],
   "source": [
    "# 2) Load configuration (API keys + DB path)\n",
    "# config.py fails fast with a helpful error message if something is missing.\n",
    "\n",
    "from src.config import GOOGLE_API_KEY, TA_API_KEY, DB_PATH\n",
    "\n",
    "print(\"Google API key loaded (length):\", len(GOOGLE_API_KEY))\n",
    "print(\"TripAdvisor API key loaded (length):\", len(TA_API_KEY))\n",
    "print(\"DB_PATH:\", DB_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "56900629",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ DB ready. Tables: ['city_top10', 'item_summary']\n"
     ]
    }
   ],
   "source": [
    "# 3) Initialize the shared SQLite database (creates the file if it doesn't exist)\n",
    "\n",
    "from pathlib import Path\n",
    "from src.db import connect, migrate_if_needed, create_tables\n",
    "\n",
    "# Ensure parent folder exists (SQLite can create the file, but not the folder)\n",
    "Path(DB_PATH).parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "conn = connect(DB_PATH)\n",
    "migrate_if_needed(conn)   # handles legacy schemas (e.g., place_ids_json -> item_ids_json)\n",
    "create_tables(conn)\n",
    "\n",
    "tables = conn.execute(\"SELECT name FROM sqlite_master WHERE type='table';\").fetchall()\n",
    "print(\"✅ DB ready. Tables:\", [t[0] for t in tables])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "45408ba1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length: 5897\n",
      "# src/pipelines.py\n",
      "\"\"\"\n",
      "Top-10 pipelines (snapshot + cache) for DABN23.\n",
      "\n",
      "This module is meant to replace the notebook-defined pipeline functions so that:\n",
      "- notebooks stay thin (just call functions)\n",
      "- snapshot + caching logic lives in src/\n",
      "- TripAdvisor group filtering is applied BEFORE snapshot is saved\n",
      "\"\"\"\n",
      "\n",
      "from __future__ import annotations\n",
      "\n",
      "from typing import Any, Dict, List, Optional\n",
      "\n",
      "from .cache import (\n",
      "    get_city_snapshot_item_ids,\n",
      "    save_city_snapshot_item_ids,\n",
      "    get_cached_item_summary,\n",
      "    upsert_item_summary,\n",
      ")\n",
      "\n",
      "from . import google_places as g\n",
      "from . import tripadvisor as ta\n",
      "\n",
      "\n",
      "def top10_google_attractions(\n",
      "    conn,\n",
      "    city: str,\n",
      "    n: int = 10,\n",
      "    language: str = \"en\",\n",
      "    search_pool: int = 50,\n",
      ") -> List[Dict[str, Any]]:\n",
      "    \"\"\"Top-N Google tourist attractions by revi\n"
     ]
    }
   ],
   "source": [
    "import src.pipelines as p\n",
    "with open(p.__file__, \"r\", encoding=\"utf-8\") as f:\n",
    "    txt = f.read()\n",
    "\n",
    "print(\"Length:\", len(txt))\n",
    "print(txt[:800])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e21d9d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4 definitions with imports\n",
    "\n",
    "from src.pipelines import top10_city\n",
    "\n",
    "ALLOW = [\"Tours\", \"Food & Drink\", \"Outdoor Activities\", \"Boat Tours & Water Sports\", \"Nightlife\", \"Shopping\"]\n",
    "DENY  = [\"Sights & Landmarks\", \"Museums\"]\n",
    "\n",
    "def city_search(city: str):\n",
    "    return top10_city(conn, city, allow_groups=ALLOW, deny_groups=DENY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cce17d1e",
   "metadata": {},
   "source": [
    "## 5) Interactive search UI (ipywidgets)\n",
    "\n",
    "Use the controls to choose:\n",
    "- city\n",
    "- data source (Google or TripAdvisor)\n",
    "- type (attraction/activity)\n",
    "\n",
    "Then click **Search Top 10**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e10d46d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90edeed573424150a756d8344e209b96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(Text(value='Paris', description='City:', layout=Layout(width='420px'), placehold…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'last_city': None, 'last_results': None}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.ui import build_city_widget\n",
    "\n",
    "LAST_SEARCHED_CITY = None\n",
    "LAST_SEARCH_RESULTS = None\n",
    "\n",
    "build_city_widget(city_search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "59ab13c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(LAST_SEARCHED_CITY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dc6c2ef",
   "metadata": {},
   "source": [
    "## 6) Optional: \"closest two\" demo (fallback)\n",
    "\n",
    "This uses a straight-line distance fallback (Haversine) so the demo works even before\n",
    "Google Routes API is integrated into `src/routing.py`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "34652b99",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'top10_google_attractions' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Example: compute closest two among Google top-10 (needs lat/lng)\u001b[39;00m\n\u001b[0;32m      4\u001b[0m city \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mParis\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 5\u001b[0m results \u001b[38;5;241m=\u001b[39m top10_google_attractions(city)\n\u001b[0;32m      7\u001b[0m start \u001b[38;5;241m=\u001b[39m results[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m      8\u001b[0m others \u001b[38;5;241m=\u001b[39m results[\u001b[38;5;241m1\u001b[39m:]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'top10_google_attractions' is not defined"
     ]
    }
   ],
   "source": [
    "from src.routing import closest_two_fallback\n",
    "\n",
    "# Example: compute closest two among Google top-10 (needs lat/lng)\n",
    "city = \"Paris\"\n",
    "results = top10_google_attractions(city)\n",
    "\n",
    "start = results[0]\n",
    "others = results[1:]\n",
    "\n",
    "closest = closest_two_fallback(start, others)\n",
    "\n",
    "print(\"Start:\", start.get(\"name\"))\n",
    "print(\"Closest two (fallback distance):\")\n",
    "for c in closest:\n",
    "    print(\" -\", c.get(\"name\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a3bdfd4",
   "metadata": {},
   "source": [
    "# Selenium"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee7aa713",
   "metadata": {},
   "source": [
    "## Selenium implementation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef446ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import sqlite3\n",
    "import datetime\n",
    "\n",
    "def get_attraction_names(city: str, conn: sqlite3.Connection):\n",
    "    \"\"\"\n",
    "    Look up stored attraction names for a city from city_top10 / ta_place_summary.\n",
    "    Returns a list of name strings, or None if city not found.\n",
    "    \"\"\"\n",
    "    citykey = city.strip().lower()\n",
    "\n",
    "    cur = conn.cursor()\n",
    "\n",
    "    # Read the stored place_ids_json for this city\n",
    "    row = cur.execute(\n",
    "        \"SELECT item_ids_json FROM city_top10 \"\n",
    "        \"WHERE city_key = ? AND source = ? AND item_type = ?\",\n",
    "        (citykey, \"google\", \"attraction\")\n",
    "    ).fetchone()\n",
    "\n",
    "    if not row:\n",
    "        # City not in DB\n",
    "        return None\n",
    "\n",
    "    place_ids = json.loads(row[0])\n",
    "    if not place_ids:\n",
    "        return []\n",
    "\n",
    "    # Fetch names in the same ranked order\n",
    "    placeholders = \",\".join(\"?\" * len(place_ids))\n",
    "    name_rows = cur.execute(\n",
    "        f\"SELECT item_id, name FROM item_summary \"\n",
    "        f\"WHERE source = ? AND item_id IN ({placeholders})\",\n",
    "        [\"google\", *place_ids]\n",
    "    ).fetchall()\n",
    "\n",
    "    name_map = {pid: name for pid, name in name_rows}\n",
    "\n",
    "    # Preserve original ranking order\n",
    "    return [name_map[pid] for pid in place_ids if pid in name_map]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f1b1cfeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TripAdvisor DB path: c:\\Users\\Samuel\\Desktop\\Git Repo\\dabn23-project1\\dabn23\\notebooks\\dabn23_tripadvisor_cache.sqlite\n",
      "Exists? True\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sqlite3\n",
    "import pathlib\n",
    "\n",
    "# Path to TripAdvisor cache in the same folder as this notebook's working dir\n",
    "TA_DB_PATH = str(pathlib.Path().cwd() / \"dabn23_tripadvisor_cache.sqlite\")\n",
    "\n",
    "print(\"TripAdvisor DB path:\", TA_DB_PATH)\n",
    "print(\"Exists?\", os.path.exists(TA_DB_PATH))\n",
    "\n",
    "taconn = sqlite3.connect(TA_DB_PATH)\n",
    "#taconn.execute(\"PRAGMA journal_mode=WAL;\")  # safe even if wal/shm files present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "087a7fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _parse_busy_bar(aria: str):\n",
    "    \"\"\"\n",
    "    Parses one peak-hours bar aria-label.\n",
    "    Handles English (\"77% busy at 2 pm\") and Swedish/Nordic (\"77 aktivitet kl. 1400.\").\n",
    "    Returns (hour_24, pct) or None.\n",
    "    \"\"\"\n",
    "    # Swedish/Nordic: \"37 aktivitet kl. 1300.\"\n",
    "    m = re.search(r\"^(\\d+)\\D+?kl\\.\\s*(\\d{2})\\d{2}\", aria.strip())\n",
    "    if m:\n",
    "        return int(m.group(2)), int(m.group(1))\n",
    "\n",
    "    # English: \"77% busy at 2 pm\"\n",
    "    m = re.search(r\"(\\d+)%.*?(\\d{1,2})\\s*(am|pm)\", aria, re.IGNORECASE)\n",
    "    if m:\n",
    "        pct, h, mer = int(m.group(1)), int(m.group(2)), m.group(3).lower()\n",
    "        hour_24 = (h % 12) + (12 if mer == \"pm\" else 0)\n",
    "        return hour_24, pct\n",
    "\n",
    "    return None\n",
    "\n",
    "\n",
    "def get_current_busyness(driver, attraction_name: str):\n",
    "    \"\"\"\n",
    "    Searches Google Maps for attraction_name and scrapes the full-day busyness.\n",
    "    Returns list[int|None] with 24 entries (index = hour 0–23),\n",
    "    or None if the place has no peak-hours section at all.\n",
    "    \"\"\"\n",
    "    print(f\"\\n  Searching: {attraction_name}\")\n",
    "\n",
    "    # 1. Navigate and type in search bar\n",
    "    driver.get(\"https://www.google.com/maps\")\n",
    "    time.sleep(2)\n",
    "    dismiss_google_consent(driver)\n",
    "\n",
    "    search_bar = WebDriverWait(driver, 10).until(\n",
    "        EC.element_to_be_clickable((By.NAME, \"q\"))\n",
    "    )\n",
    "    search_bar.clear()\n",
    "    search_bar.send_keys(attraction_name)\n",
    "    driver.find_element(By.CSS_SELECTOR, \"button.mL3xi\").click()\n",
    "    time.sleep(3)\n",
    "\n",
    "    # 2. Disambiguation list → click first result if present\n",
    "    try:\n",
    "        WebDriverWait(driver, 5).until(\n",
    "            EC.element_to_be_clickable((By.CSS_SELECTOR, \"a.hfpxzc\"))\n",
    "        ).click()\n",
    "        time.sleep(3)\n",
    "        print(\"    Clicked top result from list.\")\n",
    "    except TimeoutException:\n",
    "        print(\"    Landed directly on place page.\")\n",
    "\n",
    "    # 3. Find peak-hours section\n",
    "    try:\n",
    "        peak_section = WebDriverWait(driver, 6).until(\n",
    "            EC.presence_of_element_located((By.CSS_SELECTOR, \"div.UmE4Qe\"))\n",
    "        )\n",
    "    except TimeoutException:\n",
    "        print(\"    No peak hours data available.\")\n",
    "        return None\n",
    "\n",
    "    # 4. Parse all hourly bars into a 24-slot list\n",
    "    hourly_data = [None] * 24\n",
    "    bars = peak_section.find_elements(By.CSS_SELECTOR, \"div.dpoVLd\")\n",
    "    print(f\"    Found {len(bars)} hourly bars.\")\n",
    "\n",
    "    for bar in bars:\n",
    "        aria = bar.get_attribute(\"aria-label\") or \"\"\n",
    "\n",
    "        # Live \"Currently X% busy\" → slot into current hour\n",
    "        live = re.search(r\"(?:Currently|Nuvarande).*?(\\d+)%\", aria, re.IGNORECASE)\n",
    "        if live:\n",
    "            hourly_data[datetime.datetime.now().hour] = int(live.group(1))\n",
    "            print(f\"    ✓ Live now: {int(live.group(1))}%\")\n",
    "            continue\n",
    "\n",
    "        parsed = _parse_busy_bar(aria)\n",
    "        if parsed:\n",
    "            hour_24, pct = parsed\n",
    "            if 0 <= hour_24 <= 23:\n",
    "                hourly_data[hour_24] = pct\n",
    "\n",
    "    filled = sum(1 for x in hourly_data if x is not None)\n",
    "    print(f\"    ✓ Stored {filled}/24 hours.\")\n",
    "    return hourly_data\n",
    "\n",
    "\n",
    "def dismiss_google_consent(driver):\n",
    "    \"\"\"Dismiss the GDPR consent banner on Google Maps (EU only).\"\"\"\n",
    "    try:\n",
    "        accept_btn = WebDriverWait(driver, 8).until(\n",
    "            EC.element_to_be_clickable((\n",
    "                By.XPATH,\n",
    "                '//button[.//span[contains(text(),\"Accept all\") '\n",
    "                'or contains(text(),\"Reject all\")]]'\n",
    "            ))\n",
    "        )\n",
    "        accept_btn.click()\n",
    "        time.sleep(1)\n",
    "        print(\"  Google consent dismissed.\")\n",
    "    except:\n",
    "        print(\"  No consent popup found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9472e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "def scrape_peak_hours(city: str, conn: sqlite3.Connection):\n",
    "    \"\"\"\n",
    "    Scrapes Google Maps peak hours for all TA top-10 attractions of a city.\n",
    "    Saves results into the global `busyness_data` dict.\n",
    "    Supports multiple cities — each call adds/updates one city entry.\n",
    "    Prints the current-hour snapshot when done.\n",
    "    \"\"\"\n",
    "    scraped_at = datetime.datetime.now().strftime(\"%H:%M\")\n",
    "    city_key   = city.strip()\n",
    "\n",
    "    print(f\"Looking up '{city_key}' in  DB...\")\n",
    "    names = get_attraction_names(city_key, conn)\n",
    "\n",
    "    if names is None:\n",
    "        print(f\"  ✗ '{city_key}' not found in DB. Run the scraper first.\")\n",
    "        return\n",
    "    if not names:\n",
    "        print(f\"  ✗ No attractions stored for '{city_key}'.\")\n",
    "        return\n",
    "\n",
    "    print(f\"  Found {len(names)} attractions: {', '.join(names[:3])}...\")\n",
    "\n",
    "    attractions = {}\n",
    "    try:\n",
    "        for name in names:\n",
    "            hourly = get_current_busyness(driver, name)\n",
    "            attractions[name] = hourly   # list[int|None] or None\n",
    "            time.sleep(2)\n",
    "    finally:\n",
    "        driver.quit()\n",
    "        print(\"\\nDriver closed.\")\n",
    "\n",
    "    # Save into global dict (safe to call again for a different city)\n",
    "    busyness_data[city_key] = {\n",
    "        \"scraped_at\":  scraped_at,\n",
    "        \"attractions\": attractions,\n",
    "    }\n",
    "\n",
    "    # Print current-hour snapshot\n",
    "    now_hour = datetime.now().hour\n",
    "    print(f\"\\n{'='*54}\")\n",
    "    print(f\"  CURRENT BUSYNESS — {city_key}  (scraped at {scraped_at})\")\n",
    "    print(f\"{'='*54}\")\n",
    "    for name, hourly in attractions.items():\n",
    "        if hourly is None:\n",
    "            val = \"N/A (no GM data)\"\n",
    "        elif hourly[now_hour] is None:\n",
    "            val = \"N/A (no data this hour)\"\n",
    "        else:\n",
    "            val = f\"{hourly[now_hour]}%\"\n",
    "        print(f\"  {name:<44} {val}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9225ee6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Driver started.\n",
      "Looking up 'Paris' in TA DB...\n"
     ]
    },
    {
     "ename": "OperationalError",
     "evalue": "no such table: ta_city_top10",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[44], line 28\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m# Global storage for peak-hours data (multi-city)\u001b[39;00m\n\u001b[0;32m     27\u001b[0m busyness_data \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m---> 28\u001b[0m scrape_peak_hours(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mParis\u001b[39m\u001b[38;5;124m\"\u001b[39m, conn)\n\u001b[0;32m     30\u001b[0m driver\u001b[38;5;241m.\u001b[39mclose()\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFinished scraping.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[36], line 13\u001b[0m, in \u001b[0;36mscrape_peak_hours\u001b[1;34m(city, ta_conn)\u001b[0m\n\u001b[0;32m     10\u001b[0m city_key   \u001b[38;5;241m=\u001b[39m city\u001b[38;5;241m.\u001b[39mstrip()\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLooking up \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcity_key\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m in TA DB...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 13\u001b[0m names \u001b[38;5;241m=\u001b[39m get_attraction_names(city_key, ta_conn)\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m names \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  ✗ \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcity_key\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m not found in TA DB. Run the TA scraper first.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[33], line 15\u001b[0m, in \u001b[0;36mget_attraction_names\u001b[1;34m(city, conn)\u001b[0m\n\u001b[0;32m     12\u001b[0m cur \u001b[38;5;241m=\u001b[39m conn\u001b[38;5;241m.\u001b[39mcursor()\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# Read the stored place_ids_json for this city\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m row \u001b[38;5;241m=\u001b[39m cur\u001b[38;5;241m.\u001b[39mexecute(\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSELECT place_ids_json FROM ta_city_top10 WHERE city_key = ?\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     17\u001b[0m     (citykey,)\n\u001b[0;32m     18\u001b[0m )\u001b[38;5;241m.\u001b[39mfetchone()\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m row:\n\u001b[0;32m     21\u001b[0m     \u001b[38;5;66;03m# City not in DB\u001b[39;00m\n\u001b[0;32m     22\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;31mOperationalError\u001b[0m: no such table: ta_city_top10"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import re\n",
    "from selenium.common.exceptions import NoSuchElementException, TimeoutException\n",
    "\n",
    "options = Options()\n",
    "options.add_argument(\"--lang=en-US\")\n",
    "options.add_experimental_option(\"prefs\", {\n",
    "    \"intl.accept_languages\": \"en-US,en\",\n",
    "    \"profile.default_content_setting_values.geolocation\": 2,\n",
    "})\n",
    "options.add_argument(\n",
    "    \"--user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) \"\n",
    "    \"AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36\"\n",
    ")\n",
    "driver = webdriver.Chrome(options=options)\n",
    "driver.execute_cdp_cmd(\"Emulation.setGeolocationOverride\", {\n",
    "    \"latitude\": 40.7128, \"longitude\": -74.0060, \"accuracy\": 100\n",
    "})\n",
    "print(\"Driver started.\")\n",
    "\n",
    "# Global storage for peak-hours data (multi-city)\n",
    "busyness_data = {}\n",
    "scrape_peak_hours(\"Paris\", conn)\n",
    "\n",
    "driver.close()\n",
    "print(\"Finished scraping.\")\n",
    "# To scrape additional cities, re-run this cell with a new city name.\n",
    "# busyness_data will accumulate entries for all cities scraped this session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "04b3becb",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'datetime' has no attribute 'now'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[38], line 28\u001b[0m\n\u001b[0;32m     25\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m=== \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m  (scraped at \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mentry[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscraped_at\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) ===\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     26\u001b[0m         display(pd\u001b[38;5;241m.\u001b[39mDataFrame(rows))\n\u001b[1;32m---> 28\u001b[0m print_busyness_summary(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVenice\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[38], line 6\u001b[0m, in \u001b[0;36mprint_busyness_summary\u001b[1;34m(city)\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Print a DataFrame of current-hour busyness. Omit city= for all cities.\"\"\"\u001b[39;00m\n\u001b[0;32m      5\u001b[0m cities \u001b[38;5;241m=\u001b[39m [city] \u001b[38;5;28;01mif\u001b[39;00m city \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(busyness_data\u001b[38;5;241m.\u001b[39mkeys())\n\u001b[1;32m----> 6\u001b[0m now_hour \u001b[38;5;241m=\u001b[39m datetime\u001b[38;5;241m.\u001b[39mnow()\u001b[38;5;241m.\u001b[39mhour\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m cities:\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbusyness_data is empty — run scrape_peak_hours() first.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'datetime' has no attribute 'now'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def print_busyness_summary(city: str = None):\n",
    "    \"\"\"Print a DataFrame of current-hour busyness. Omit city= for all cities.\"\"\"\n",
    "    cities = [city] if city else list(busyness_data.keys())\n",
    "    now_hour = datetime.now().hour\n",
    "\n",
    "    if not cities:\n",
    "        print(\"busyness_data is empty — run scrape_peak_hours() first.\")\n",
    "        return\n",
    "\n",
    "    for c in cities:\n",
    "        if c not in busyness_data:\n",
    "            print(f\"No data for '{c}'.\")\n",
    "            continue\n",
    "        entry = busyness_data[c]\n",
    "        rows = []\n",
    "        for name, hourly in entry[\"attractions\"].items():\n",
    "            pct = None if (hourly is None) else hourly[now_hour]\n",
    "            rows.append({\n",
    "                \"Attraction\":           name,\n",
    "                f\"Busy at {now_hour:02d}:00\": f\"{pct}%\" if pct is not None else \"N/A\",\n",
    "                \"Has full-day data\":    hourly is not None,\n",
    "            })\n",
    "        print(f\"\\n=== {c}  (scraped at {entry['scraped_at']}) ===\")\n",
    "        display(pd.DataFrame(rows))\n",
    "\n",
    "print_busyness_summary(\"Venice\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
